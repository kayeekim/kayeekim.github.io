---
layout: post
title:  "[DL] RNN"
excerpt: "Deep Learning Basic - RNN"

categories:
  - ds
tags:
  - [DL]

toc: true
toc_sticky: true
 
date: 2022-04-08
last_modified_at: 2022-04-08

---

## Summary 
* 
* RNN 기본 개념

# 시계열 분석 알고리즘 종류
## Statistic based
* Moving Average
* Exponential Smoothing
* ARIMA (Autoregressive integrated moving acerage)
* SARIMA (Seasonal ARIMA)
* Binary variable model
* Trigonometric model
* Growth curve model
* Time series regression with autocorrelation

## ML based
* Support Vector Machine/Regression
* Random Forest
* Boosting
* Gaussian Process
* Hidden Markov Model

## DL based
* Recurrent neural network (RNN)
* LSTM
* GRU
* Seq2Seq, Seq2Seq with Attention
* Transformer
* GPT-1, BERT, GPT-3

# What is a Recurrent Neural Network (RNN)
## Feedforward Neural Networks vs Recurrent NNs 
### RNN의 핵심 아이디어
* Neuron 에 시퀀스가 처리될 때 업데이트 되는 "내부 상태" 개념이 존재
* 시퀀스가 처리될 때 마다 업데이트 된다 = 데이터가 순환된다 => 과거의 정보를 기억 + 최신 데이터 반영 (update)
* 모든 time step 에서의 반복 공식
    * $ h_t = f_W(h_(t-1), x_t) $  where $h_t$: new state; state at time step t / $f_W$: some function with parameters W / $h_(t-1)$ : old state; state at time step t-1 / $x_t$: input vector at time step t
    * 모든 time step 에서 동일한 $f_W$ (function with parameters W) 가 사용 =  "activate function and weight" sharing

### Process Sequence + 예시
#### Feedforward NNs
* one to one: Image clasification (Image -> Label)

#### Recurrent NNs (순환신경망)
* one to many: Image Captioning (Image -> Sequence of words)
* many to one: Video classification (Sequence of images -> label)
* many to many
    * Machine Translation (Sequence of words -> Sequences of words)
    * Per-frame video classification (Sequence of images -> Sequence of label) 

# RNN 기반 알고리즘 종류
## Vanilla RNN (Same as "Elman RNN")
* The state consists of a single "hidden" vector h:
    * $h_t = f_W(h_(t-1), x_t)$
    * => (Vanilla/Elman) $h_t = tanh(W_(hh) h_(t-1) + W_(xh) x_t)$ where $W_(hh)$: weight of hidden to hidden / $W_(xh)$: weight of input to hidden
    * $y_t = W_(hy) h_t$ where $W_(hy)$: weight of hidden to output

## Sequence to Sequence (Seq2Seq)
* Many to Many: Many to one (Encoder) + One to many (Decoder)
    * Many to one (Encoder) : input sequence (X = (x1, x2, ...) -> 단일 벡터 ( Context Vector ; encoder의 마지막 time step의 hidden state) 로 인코딩
    * One to many (Decoder) : 단일 입력 벡터 에서 output sequence (Y = (y1, y2, ...) 생성
* Language Model 예제 (출처. [부스트캠프 AI Tech] U-stage. 4-3)
    * ![image](https://user-images.githubusercontent.com/98376833/162370771-ebad80d2-a4b0-4c40-ae0d-70de99926d55.png)
    * Encoder: 
        * RNN 셀의 마지막 hidden state(Context Vector) 를 decoder의 입력으로 들어가게 된다.
        * ![image](https://user-images.githubusercontent.com/98376833/162372338-994382c2-9042-42bc-9588-5b4057fcc430.png) 
    * Decoder: 
        * Decoder 는 encoder가 넘겨준 context vector 를 RNN 셀의 첫번째 hidden state로 사용한다. 
        * ![image](https://user-images.githubusercontent.com/98376833/162372466-fddc9bbe-cf2c-49d4-9d61-18d32394cb08.png)
        * ![image](https://user-images.githubusercontent.com/98376833/162372580-80a91140-aa32-45d9-b6c2-5802780a8bd8.png)
        * Train 시, 학습과정에서의 decoder는 encoder로 부터 받은 context vector 와 실제 정답 상황인 <sos> je suis étudiant를 입력으로 주는 teacher forcing 기법을 통해 je suis étudiant <eos> 가 나오도록 학습한다.
        * Test 시, Test 과정에서는 context vector 와 <sos> 토큰 (Output sentence의 첫번째 토큰) 만을 입력으로 받아 다음에 등장할 확률이 높은 단어를 예측하여 그 결과를 다음 time step으로 넣어주고 <eos> 토큰이 다음 단어로 예측 될때까지 이 과정을 반복한다.
        
  
---

#### Reference
* Seq2Seq ([부스트캠프 AI Tech] U-stage. 4-3) https://velog.io/@kgh732/%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BA%A0%ED%94%84-AI-Tech-U-stage.-4-3
