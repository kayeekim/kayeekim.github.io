---
layout: post
title:  "[DL] Neural Netowrk 기본과 CNN"
excerpt: "Deep Learning Basic - Neural Netowrk 기본과 CNN"

categories:
  - ds
tags:
  - [DL]

toc: true
toc_sticky: true
 
date: 2022-04-05
last_modified_at: 2022-04-21

---

## Summary 
* MLP 기본 개념 - Perceptron 계산 구조
* CNN 기본 개념

# What is a Neuron Model
## Neuron Model (What are Artificial Neural Network and Perceptron)
* 생물의 뉴런에서 착안된 모델
* Perceptron 모델의 구성 요소: 1) Synapses, 2) Adder and 3) Activation function 기반으로 모델의 perceptron 구성
* 여러 개의 perceptron 을 이용하여 하나의 layer 를 구성
    * Kaye - 하나의 perceptron 은 layer 내 hidden node 역할을 하게된다.
* Single-layer Feedforward network: 1-layer Network
* Multi-Layer Perceptron (MLP): Multi-layer Network *참고: Deep Neural Network: 주로 hidden layer 갯수가 2개 이상인 모델을 DNN이라 부름.

### 가장 기본적인 Perceptron 계산 구조 ( - Kaye) NN 전체 구조에서 하나의 hidden node 가 하는 일)
* Input Node를 통해 input signal x={x1, x2, ..., xn} 이 들어오면
* Synaptic Weights w={w1, w2, ...., wn} 과 
* (Adder; Summation 수행) Weighted SUM 계산. s=x1w1+x2w2+...xnwn+b where b: bias
* Activation function 을 통해 (주로 non-linear function 사용) perceptron의 output h(x) 도출
* (+) (synapse) 를 통해 output h(x)를 다음 뉴런 (perceptron) 의 input 으로 전달
* h(x) = activate(WX+b) (= activate[{ SUM of (wi*xi) } + b])

# What is a Convolutional Neural Network (CNN)
* 원 Paper: Lecun (1989), Backpropagation applied to handwritten zip code reconition

## CNN 특징
### CNN vs MLP (Fully Connected Layer 모델) - CNN이 가지는 MLP 와의 차이점
* 1) Local Connectivity
    * Layer의 각 node들이 모든 input node에 연결되는 것이 아닌 **(특정 영역 내) local region 내 input node 에만 연결**
* 2) Weight Sharing
    * weight 가 공유된다. 
    * 도입 가정: 특정 위치의 pixel 이 왼쪽 옆 pixel의 영향을 받는다면, 이 영향은 이미지의 다른 위치에서도 유효할 것이다.
    * Kaye) Input value size 가 큰 경우 (e.g. pixel 갯수, feature 갯수), 각 input node와 연결되는 weight를 개별적으로 부여하게 되면 Weight 갯수가 많아진다 --> MLP 
    * Kaye) Weight의 갯수를 조절하기 위해 CNN 에서는 Weight Sharing 개념을 도입하였다 - CNN filter 내 weight가 있고, 이 필터가 이미지를 슬라이딩하며 벡터의 내적 (weighted sum) 값을 계산하게 된다.
    * 예시) Image size: 32*16*3 이고 (hidden) output size = 100 이라고 한다면 , 계산에 필요한 Weight 수: (MLP) 32*16*3*100
* 3) Subsampling (== Pooling)
    * hidden feature 갯수를 효율적으로 줄이기 위해 pooling 도입 *Kaye) pooling 사용은 선택

### CNN 기반 Feature 추출 시 특징
* Low Level Feature Extraction: 하위 layer 일수록 (Input Layer 와의 연결이 가까울수록), 특징이 큰 feature 추출 (e.g. Edge 에 대한 성분 - 선, 곡선, 색)
* High Level Feature Extraction: 상위 layer로 갈수록 (Output Layer 와의 연결이 가까울수록), 점점 추상화된 feature 추출 (e.g. 세부 Object 에 대한 성분 - 눈, 코, 입)

### CNN 동작원리
* 1) 이미지를 작은 영역으로 나누고 (CNN 필터; Convolution Filter 가 커버하는 영역), Small Network 구조를 통해 (= CNN; 합성곱; Convolution Filter 활용) 나뉘어진 영역에서 Feature 추출 (e.g. 눈에 대한 feature) (==> Local Connectivity)
* 2) Convolution Filter 를 다음 영역으로 이동하면서 같은 방법으로 Feature 추출. *이 때, Convolution Filter의 Weight는 동일* (==> Weight Sharing)
* 3) 다른 feature (e.g. 코에 대한 feature) 를 추출하기 위한 Convolutiona Filter 로  "1), 2)" 수행
* 4) 3)에서 추출된 모든 feature 들로부터 최종 이미지 분류/예측 수행 *kaye) 최종 분류/예측 시엔 Fully Connected Layer 등을 활용

## CNN 기반 이미지 분석 
* Feature Learning
* Classification

### Feature Learning (Convolution Layer)
* Convolution
* Activation : ReLU, etc.
* Pooling
#### Convolution
* 여러 개의 filter 를 사용해서 feature 추출

#### Activate Function

#### Pooling
*  데이터의 크기를 감소 (정보 축약) 
*  Pooling의 경우 필수로 사용할 필요는 없다. 데이터의 크기를 줄이고 싶을 때 선택적으로 이용하면 된다. 

### Classification
* Flatten Operation
* Fully Connected Layer
* Softmax

#### Flatten 
* 특징 벡터들을 하나의 **열(벡터)** 로 평탄화

#### Fully Connected
* Same as Multi Layer Perceptron (MLP)
* 모든 input neurons 가 다음 층의 모든 neurons 와 연결

#### Softmax (for Classification)
![image](https://user-images.githubusercontent.com/98376833/164365013-19bda9db-7ca8-42a8-b381-1438870dc8b4.png)

* K개의 값 (이전 층의 결과 e.g. activation value) 이 존재할 때, 각각의 값의 편차를 확대하는 효과. - 큰 값은 상대적으로 더 크게, 작은 값은 상대적으로 더 작게 
    * K: # of classes 
* Sum 값으로 나눠줌으로써 정규화 효과 - Softmax 함수를 거친 K 개의 합은 1


