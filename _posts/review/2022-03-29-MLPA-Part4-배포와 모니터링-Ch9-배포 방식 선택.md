---
layout: post
title:  "[MLPA] Part4/Ch.9 - 배포 방식 선택 (+ 모델 경량화, 연합학습 간략 설명) "
excerpt: "Building Machine LEarning Powered Applications - Part4 - Ch.9 정리"

categories:
  - review
tags:
  - [Books]

toc: true
toc_sticky: true
 
date: 2022-03-29
last_modified_at: 2022-03-29

---

* 해당 블로그는 책 '머신러닝 파워드 애플리케이션 (한빛미디어)' 을 읽고 개인적으로 정리한 글입니다.

* 번역서 코드 주소: https://github.com/rickiepark/ml-powered-applications

#### 머신러닝 전체 과정
Part 1 - 올바른 머신러닝 접근 방법 모색
Part 2 - 초기 프로토타입 제작
Part 3 - 모델 반복
**Part 4 - 배포와 모니터링**

# Part 4 - 배포와 모니터링
* Ch.8 모델 배포 시 고려 사항: 배포 전 마지막 검증 과정 수행 (모델 남용, 부적절 사용 조사 / 안전장치 예상 및 구축)
* Ch.9 배포 방식 선택: 모델을 배포하기 위한 여러가지 도구와 플랫폼 설명 및 그 중 하나를 선택하는 방법
* Ch.10 모델 안전장치 만들기: 모델을 지원할 수 있는 안정적인 제품 환경 구축. 모델 실패를 감지하여 처리 / 모델 성능 최적화 / 반복 훈련 시스템화 포함
* Ch.11 모니터링과 모델 업데이트: 모니터링 / 모니터링 해야하는 이유 / 모델을 모니터링하기 위한 최선의 방법 / 배포 전략에 모니터링 설정을 결합하는 방법 소개.

---

## Ch.9 배포 방식 선택
### Summary (+ 9.4. 마치며)
* 요구 사항 마다 적합한 배포방식이 다르다 - 배포 방식을 선택할 때 속도, 하드웨어, 네트워크 요구 사항, 개인정보 보호, 비용, 복잡도 같은 여러 가지 요인을 고려한다.
* 모델 배포의 목적: 사용자에게 제공하기 위함
* 9.1. 서버 측 배포 server-side deployment
    * A. 스트리밍 애플리케이션 또는 API, 모델을 엔드포인트로 간주: 모델의 필요한 정보가 도착하는 대로 샘플 처리 가능
    * B. 배치 워크플로: 정기적인 스케줄에 따라 한번에 여러 데이터 샘플 처리 가능
* 9.2. 클라이언트 측 배포: 장점 - 추론 비용과 인프라 요구 사항 감소 / 단점 - 배포과정 복잡
    * C. 온 디바이스, 애플리케이션에 패키징 
        * 고려사항: 모델 경량화
        * 활용 가능 라이브러리: TensorFlow Lite
    * D. 브라우저 (웹 브라우저)
        * 활용 가능 프레임워크: TensorFlow.js
* 9.3. 연합 학습 (하이브리드 방법)
    * 클라이언트를 모델의 배포를 위해서만 생각하는 것이 아닌 (9.2), 
    * 클라이언트 별 모델을 가지고 있고 & 각자의 모델에 대한 '훈련'도 함께 수행 
    * 훈련된 개별 모델에서 요약 수집된 업데이트를 서버로 보냄
    * 서버는 모든 업데이트를 사용해 모델을 향상. 새로운 모델의 업데이트를 개별 클라이언트에 다시 전달

### 9.1. 서버 측 배포 server-side deployment
-. 서버 측 배포 server-side deployment 는 client 로부터 요청을 받아 추론 파이프라인을 실행하여 결과를 반환하는 웹 서버로 구성

-. 웹 개발 패러다임에 적합 - **모델을 애플리케이션에 있는 하나의 endpoint 로 다루기 때문** 

-. 사용자는 endpoint 로 요청을 보내고 결과를 기대.

-. 작업으로는 스트리밍 streaming / 배치 batch 두 가지 종류가 있다.
* Streaming 방식: 요청을 받자마자 즉시 처리. 속도에 대한 요구사항이 높을 때 필요. 모델에서 **필요한 정보가 예측 시점 에서 제공** & 모델의 **예측이 즉시 필요한 경우** 스트리밍 방식이 적합.
* Batch 방식: 덜 빈번하게 실행. 한 번에 많은 개수의 요청 처리. 예측을 계산하는 데 **필요한 정보를 미리 얻을 수 있는 경우** & 모델의 요청을 도착하는 대로 처리하는 것이 아닌 **한번에 많은 양의 요청을 처리할 수 있는 경우** 배치 방식이 적합.

-. 배포를 하기 위한 호스팅 서버가 필요. 예측 요청이 증가함에 따라 서버에 사용되는 비용이 빠르게 증가할 수 있다.


#### 9.1.1 스트리밍 애플리케이션 또는 API (스트리밍 방식)
-. 스트리밍 방식: **모델을 사용자가 요청을 보낼수 있는 엔드포인트로 간주**

-. 속도에 대한 요구사항이 높을 때 필요. 모델에서 **필요한 정보가 예측 시점 에서 제공** & 모델의 **예측이 즉시 필요한 경우** 스트리밍 방식이 적합.

-. 스트리밍 애플리케이션 요청 순서 (스트리밍 API 워크플로)
* 0) 사용자가 전송한 요청 수신
* 1) 요청 검사: 전달된 매개변수값 검사. 사용자가 이 모델을 실행할 권한이 있는지 확인.
* 2) 필요 데이터 수집 (w. 데이터 저장소): 추가로 필요한 데이터 수짐. 다른 데이터 소스에 필요한 추가 데이터를 요청 (e.g. 사용자 관련 정보)
* 3) 데이터 전처리
* 4) 모델 실행
* 5) 출력 후처리: 결과가 허용 가능 범위 내인지 확인. 모델의 신뢰도와 같이 사용자가 결과를 이해할 수 있도록 설명 추가
* 6) 결과 전송

-. 엔드포인트 방식 장,단점
* 장점: 구현이 빠름
* 단점: 사용자가 개별적인 추론 요청을 보내기 때문에 동시 사용자 수에 맞춰 선형적으로 인프라를 늘려야 함. 파이프라인을 트래픽 패턴에 적용하기 위해 새로운 서버를 쉽게 시작하고 종료할 수 있어야 함 (=> 일정 수준의 자동화 필요). 

-. 웹 개발 배포 방법 중 Flask 플라스크 - 경량 파이썬 웹 애플리케이션 프레임 워크
* API: 요청을 받아 모델로 보내 플라스크로 처리
* HTML: 사용자가 텍스트를 입력하고 결과를 출력하기 위한 웹사이트 창 구현

```python
# app.py
## API 정의 -머신러닝 에디터 버전 3을 서비스하는 두 함수
### https://github.com/rickiepark/ml-powered-applications/blob/main/app.py

from flask import Flask, render_template, request

@app.route("/v3", methods=["POST", "GET"])
def v3():
    """
       Renders v3 model input form and results 
       사용자가 /v3 페이지에 접근할 때 보여질 html을 결정하는 route 정의
    """
    return handle_text_request(request, "v3.html")

def handle_text_request(request, template_name):
    """
    Renders an input form for GET requests and displays results for the given
    posted question for a POST request
    :param request: http request
    :param template_name: name of the requested template (e.g. v2.html)
    :return: Render an input form or results depending on request type
    """
    if request.method == "POST":
        question = request.form.get("question")
        model_name = get_model_from_template(template_name) # Get the name of the relevant model from the name of the template
        suggestions = retrieve_recommendations_for_model(question, model_name) # This function computes or retrieves recommendations
        payload = {
            "input": question,
            "suggestions": suggestions,
            "model_name": model_name,
        }
        return render_template("results.html", ml_result=payload)
    else:
        return render_template(template_name)
 
```

```html
--v3.html
---- HTML 템플릿 - 사용자에게 보여지는 화면
---- https://github.com/rickiepark/ml-powered-applications/blob/main/templates/v3.html

<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <title>머신러닝 에디터</title>
  </head>
  <body>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

    <h1>머신러닝 에디터에 오신 것을 환영합니다!</h1>
    <h2>버전 3: 향상된 모델에서 얻은 추천을 적용합니다.</h2>
    <p> 이 버전의 머신러닝 에디터는 질문 품질 점수와 여러 추천을 춢력합니다.
        점수와 추천 모두 <a href="writers.stackexchange.com">writers.stackexchange.com</a>의
        질문 데이터셋에서 훈련된 모델로 구합니다.
        점수 모델은 질문이 평균적으로 더 많은 찬성(upvote) 개수를 받을지 예측하도록 훈련됩니다.
        설명 모델은 현재 예측 점수를 향상할 수 있는 가능성이 높은 추천을 생성하도록 훈련됩니다.
        이 데이터셋에 있는 질문은 (여러 개의 문장으로 구성되어) 긴 편이므로 샘플이 길 경우 잘 맞습니다.</p>
    <p>일부 경우 추천이 낮은 점수를 내도록 만들 수 있습니다.
      이는 설명 모델의 추정 오류이거나 우연히 나쁜 영향을 끼치는 다른 특성 때문일 수 있습니다.
      이 문제를 완화하려면 개선 과정을 여러번 반복하는 것이 좋습니다.</p>
    <form action="" method="post">
        <div class="form-group">
            <label for="question">질문할 내용을 입력해 주세요.</label>
            <textarea class="form-control" rows="5" name="question" ></textarea>
        </div>
        <button type="submit" class="btn btn-primary">추천 요청 (1분정도 걸립니다)</button>
        <a href="/" class="btn btn-primary">메인 페이지로 돌아가기</a>
    </form>

  </body>
</html>

```                                                                      

#### 9.1.2. 배치 예측
-. 배치 방식: **추론 파이프라인을** 여러 샘플에서 동시에 실행할 수 있는 하나의 **잡 job 으로 간주**

-. 속도에 대한 요구사항이 높지 않으면서, 예측을 계산하는 데 **필요한 정보를 미리 얻을 수 있는 경우** & 모델의 요청을 도착하는 대로 처리하는 것이 아닌 **한번에 많은 양의 요청을 처리할 수 있는 경우** 배치 방식이 적합.

-.배치 방법은 스트리밍 방식과 동일한 횟수만큼 추론 실행

-.배치 방식 장,단점
* 장점
    * 자원을 효율적으로 사용 - 사전에 지정된 시간에 예측이 수행되고 배치 작업 시 예측 갯수를 알 수 있기 때문에 자원을 할당하고 병렬화하는게 용이.   
    * 추론 속도가 빠름 - 미리 계산된 결과를 저장하고, 추론 시에는 저장한 내용을 추출 (*캐싱의 장점와 유사)

-. 배치 워크플로 예시
* 배치 시간: 모든 데이터 포인트에 대한 예측을 계산하여 결과 저장
* 추론 시간: 미리 계산된 결과를 추출
![image](https://user-images.githubusercontent.com/98376833/160614785-41980ed8-cc93-4343-9a22-aa8b38f33419.png)

#### 9.1.3 서버 측 배포 방법 내 하이브리드 방식 (배치 + 스트리밍)
-. 배치 파이프라인 + 스트리밍 파이프라인
  * 배치 방식 : 가능한 많은 샘플을 미리 계산하여 추론 시에 사전에 계산된 결과 추축
  * 스트리밍 방식 : 만약 사전에 계산한 결과가 없거나 오래되었따면 즉시 계산 수행

-. 하이브리드 방식 장,단점
* 장점: 계산할 수 있는 모든 것을 미리 수행하기 때문에 가능한 한 신속하게 결과 제공
* 단점: 배치 파이프라인과 스트리밍 파이프라인을 모두 유지하기 위한 고비용, 높은 복잡도


### 9.2. 클라이언트 측 배포 (추론을 위해 훈련된 모델을 장치에 배포)
-. 요청을 서버가 아닌 클라이언트 장치에서 직접 처리. 

-. 사용자 장치에서 모델을 실행함으로서 추론 비용 감소, (애플리케이션 인기도와 상관없이) 일정 수준 서비스 유지가 가능

-. (9.2장) 모델 훈련 - 서버 / 추론 - 클라이언트 (컴퓨터, 태브릿, 스마트폰 등 네트워크에 연결된 클라이언트 장치)

-. 애플리케이션에 모델을 패키징하는 워크플로 예시
![image](https://user-images.githubusercontent.com/98376833/160617751-aaab0460-0347-4f04-a77c-b71fe1aea465.png)

-. (9.1. 서버 측 배포 대비) 장, 단점
* 장점:
    * 모든 사용자에 대한 추론을 실행하기 위해 인프라를 구축할 필요가 없다
    * 장치에서 모델을 실행하므로 장치와 서버 사이에 전송할 데이터 양이 줄어든다
    * 데이터 보호 - 추론에 필요한 데이터를 원격 서버로 전송할 필요가 없다.
* 단점: 모델의 복잡도 제한 (장치의 컴퓨팅 성능에 좌우)
* 일반적으로 "클라이언트 측 모델 처리 지연 시간 (장치에서 추론 실행 시간) > 서버 측 모델 네트워크 지연 시간" 보다 긴 경우, **서버 (혹은 클라우드) 에서 모델 실행하는 것 고려**
* 사용 모델의 크기가 <= 몇 메가바이트 OR 빠르게 다운로드가 가능하다면 **클라이언트에서 모델 실행하는 것 고려**

![image](https://user-images.githubusercontent.com/98376833/160619836-18ee1977-7425-42e7-957f-9e7bedbcc1df.png)

-. 작업으로는 온 디바이스 On-device, 브라우저를 통해 실행하는 방법 두 가지 종류가 있다.
* 온 디바이스 On-device: 모델을 직접 배포
* 브라우저: 모델이 자바스크립트를 사용해 브라우저에서 구동되어 사용자 장치에서 계산 수행

#### 9.2.1. 온 디바이스 On-device
-. 장치 컴퓨팅 성능에 맞춰 모델 경량화 필요

-. 온 디바이스 방법의 장, 단점
* 장점: 속도, 인프라, 개인 정보에 대한 이득이 큼
    * 예측 정확도가 희생되더라도 장치에 배포할 수 있는 모델이 필요한 경우
        * 예시) 인터넷 연결 없이 실행할 수 있는 로컬 모델 (번역 앱, 등산 앱 등)
    * 데이터의 민감한 경우 - 온 디바이스 방법의 경우, 민감한 데이터를 장치로부터 떠나지 않도록 할 수 있음.
* 단점: 
    * 모델 경량화하는데 작업시간 소요
    * 모델을 최적화하는 과정에 시간이 소요될 수 있음

##### 모델 경량화 방법
* 간단한 모델 사용 OR 모델의 파라미터 갯수나 계산 정밀도를 줄임 OR 모델의 사용하는 Feature 갯수를 줄이기
* (예시) 신경망에서 경량화 하는 방법
    * 가중치 가지치기 (0에 가까운 가중치 삭제
    * 가중치 값 압축 (가중치의 부동소수점 정밀도를 낮춤)
* TensorFlow Lite 라이브러리: 모델의 크기를 줄여 모바일 장치에 쉽게 배포하도록 돕는 도구 제공

##### Appendix. Tensorflow Lite
* Reference LINK.
    * https://www.tensorflow.org/lite

#### 9.2.2. 브라우저 Browser
-. 온 디바이스 방법에서 필요한 엔지니어링 작업을 줄이기 위해 파생된 방법

-. 스마트폰에서 지원하는 브라우저의 경우, 종종 빠른 그래픽 계산을 지원하기 위해 최적화되어 있음.

-. TensorFlow.js: 브라우저를 사용해 머신러닝 작업을 수행하는 프레임워크

-. 사용자는 추가적인 애플리케이션 설치 없이 브라우저를 통해 모델과 상호작용 가능

-. 모델이 자바스크립트를 사용해 브라우저에서 구동되기 때문에 사용자 장치에서 계산이 수행됨.

-. (온디바이스 방법 대비) 브라우저 방법의 장, 단점
* 장점: 장치에 특화시키기 위해 필요한 엔지니어링 작업을 줄일 수 있음
* 단점: 대역폭 비용 증가 - 온디바이스는 모델을 한번만 다운/ 브라우저는 웹 페이지를 열때마다 모델 다운

##### Appendix. Tensorflow.js
* 대부분의 미분가능한 모델을 브라우저에서 자바스크립트로 훈련하거나 추론 실행 가능
* 파이썬 같은 다른 언어로 훈련된 모델도 사용 가능
* WebGL 을 지원하고 있어 클라이언트 장치에 있는 GPU 사용 가능
* Reference LINK.
    * https://www.tensorflow.org/js


### 9.3. 연합 학습 Federated Learning: 하이브리드 방법 (서버 측 배포 + 클라이언트 측 배포)
-. 클라이언트에서 클라이언트 별 모델 '훈련'도 일부 수행

-. 결론적으로 '훈련'이 서버 (general 모델) + 클라이언트 (custom 모델) 함께 진행

![image](https://user-images.githubusercontent.com/98376833/160626074-ef50ca0c-dd04-4657-85a2-389080e65908.png)

-. 연합학습 개념
* a) 각 클라이언트는 각자의 모델 (개인화된 모델)을 가진다
* b) 각각의 모델은 사용자의 데이터에서 학습된다.
* c) 학습된 각각의 모델에서 요약 수집된 (+ 익명화된) 업데이트를 서버로 보낸다.
    * (중요) 이 때, 사용자 데이터는 서버로 전송하지 않고 집계뙨 모델 업데이트만 서버로 보낸다. <- 개인 정보 보호 향상
* d) 서버는 각 모델에서 온 모든 업데이트를 사용해 모델을 향상시킨다.
* e) 새로운 모델의 업데이트를 개별 클라이언트에 다시 전달한다.
* 위 a) ~ e) 과정을 통해 사용자는 각자의 요구에 맞는 개인화된 모델을 받으면서, 여전히 다른 사용자로부터 집계된 정보에서 도움을 받는다. 

-. 연합학습의 장, 단점
* 장점: 개인화된 모델 사용 / 데이터 보호
* 단점: 복잡성이 높다 - 개별 모델이 잘 동작하면서 서버로 전송된 데이터를 적절하게 익명화시키는 것은 단일 모델을 훈련하는 것보다 더 복잡하다.

##### Appendix. 연합 학습이란
* Reference LINK. 
    * https://kayeekim00.github.io/AI-federated-learning/
    * 연합 학습(Federated Learning), 그리고 챌린지 LINK. https://medium.com/curg/%EC%97%B0%ED%95%A9-%ED%95%99%EC%8A%B5-federated-learning-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EC%B1%8C%EB%A6%B0%EC%A7%80-b5c481bd94b7

---
