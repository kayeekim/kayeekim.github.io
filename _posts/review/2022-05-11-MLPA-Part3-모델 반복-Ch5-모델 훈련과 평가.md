---
layout: post
title:  "[MLPA] Part3/Ch.5 - 모델 훈련과 평가 "
excerpt: "Building Machine LEarning Powered Applications - Part3 - Ch.5 정리"

categories:
  - review
tags:
  - [Books]

toc: true
toc_sticky: true
 
date: 2022-05-11
last_modified_at: 2022-05-11

---

* 해당 블로그는 책 '머신러닝 파워드 애플리케이션 (한빛미디어)' 을 읽고 개인적으로 정리한 글입니다.

* 번역서 코드 주소: https://github.com/rickiepark/ml-powered-applications

#### 머신러닝 전체 과정
Part 1 - 올바른 머신러닝 접근 방법 모색
Part 2 - 초기 프로토타입 제작
**Part 3 - 모델 반복**
Part 4 - 배포와 모니터링

# Part 3 - 모델 반복
* Ch.8 모델 배포 시 고려 사항: 배포 전 마지막 검증 과정 수행 (모델 남용, 부적절 사용 조사 / 안전장치 예상 및 구축)
* Ch.9 배포 방식 선택: 모델을 배포하기 위한 여러가지 도구와 플랫폼 설명 및 그 중 하나를 선택하는 방법
* Ch.10 모델 안전장치 만들기: 모델을 지원할 수 있는 안정적인 제품 환경 구축. 모델 실패를 감지하여 처리 / 모델 성능 최적화 / 반복 훈련 시스템화 포함
* Ch.11 모니터링과 모델 업데이트: 모니터링 / 모니터링 해야하는 이유 / 모델을 모니터링하기 위한 최선의 방법 / 배포 전략에 모니터링 설정을 결합하는 방법 소개.

---

## Ch.5 모델 훈련과 평가
### Summary (+ 5.4. 마치며)
* Part 2 요약: 문제 정의, 문제 해결 계획 세우기, 데이터셋 탐색, 초기 특성 생성 --> 적절한 모델을 훈련하기 위한 충분한 정보 획득
* (해당 장에서 설명하는) 적절한 모델이란? 현재 작업에 적합하고 좋은 성능을 낼 가능성이 높은 모델
* 모델 선택 시 고려 사항
* 모델 평가 시 데이터 분할 방법
* 모델 결과 분석 및 오차 진단

### 5.1. 가장 간단하고 적절한 모델
* 가능한 모든 모델로 시도 및 TEST dataset 의 특정 측정 지표 기준으로 결과를 평가하는 경우 --> 일반적으로 이 방법이 최선이 아님
    * 계산 비용이 높음
    * 모델을 블랙박스 처럼 다룸
    * **머신러닝 모델이 학습하는 과정에서 암묵적으로 데이터에 대해 어떤 가정을 한다는 것**을 완전히 무시 
* 모델마다 데이터에 대한 가정이 다르므로 적합한 작업이 따로 존재

#### 5.1.1. 간단한 모델
* 간단한 모델이란? 1) 빠른 구현 2) 쉬운 이해 3) 배포 가능
* 단순성 비교를 위해 주어진 문제에 맞는 자신만의 비교 표를 만드는 것도 좋음
* 비교 표 항목 예시
    * 1) 구현의 용이성
        * 1-1) 이해하기 쉬운 모델
        * 1-2) 검증된 구현
    * 2) 해석 능력
        * 2-1) 특성 중요도 추출 용이
        * 2-2) 디버깅하기 쉬움
    * 3) 배포 능력
        * 3-1) 추론 시간
        * 3-2) 훈련 시간

##### 1) 빠른 구현 (구현의 용이성)
* 구현이 간단한 모델: 이해하기 쉽고, 튜토리얼에 많이 사용되고, 도움을 얻을 수 있는 모델
* e.g. Keras, Scikit-learn 과 같이 이미 잘 알려진 라이브러리에 있는 모델 사용

##### 2) 쉬운 이해 (해석 능력)
* 모델의 설명 가능성 explainability & 해석 능력 interpretability 란? 예측을 만들게 된 이유 제시 (e.g. 특성 조합 like feature importance)
* 모델의 Explainability 를 통해
    * 모델 편향 확인
    * 예측 결과 향상 방향성 확인
    * 반복과 디버깅 용이
* 모델의 Interpretability 를 통해
    * 더 나은 선택을 하도록 특성 추가, 변경, 제거 방향성 확인 

##### 3) 배포 가능 (배포 능력)
* 모델의 최종 목표는 **사용자에게 가치 있는 서비스를 제공하는 것**
    * 예측 속도: 훈련된 모델이 사용자에게 예측을 제공하는데 시간이 얼마나 소요되는가?  
        * 모델 결과 출력 소요 시간 + 사용자가 요청을 보내고 결과를 받는 과정 소요 시간
        * 변수 전처리, 네트워크 전송, 모델 출력, 사용자에게 보여질 데이터 사이에 필요한 후처리 단계 포함
    * 예상하는 동시 접속자 수 고려: 동시 접속자 수 고려 시 추론 파이프라인이 충분히 빠른지
    * 모델 훈련 시간: 모델 훈련하는데 소요되는 시간, 얼마나 자주 훈련해야하는지 등

#### 5.1.2. 패턴에서 모델로
* 데이터 내 패턴에 따른 적절한 모델 예시

##### 1) Feature (특성) 들 간 Scale 차이가 큰 경우
* 방법 1) 정규화
* 방법 2) 특성 스케일의 차이에 영향을 받지 않는 모델 선택
    * e.g. Tree 계열: Decision Tree, Random Forest, Gradient Boosted Decision Tree, XGBoost
    *  _XGBoost: 그래디언트 부스팅 트리 타입 중 하나로 안정성이 높고 속도가 빨라 실전에서 널리 사용됩니다_

##### 2) Target (Y) 이 Features (Xs) 의 선형 조합인 경우
* 특성의 선형 조합만 사용해 좋은 예측이 가능하다고 판단 되는 경우
* 회귀문제: Linear Regression / 분류문제: Logistic Regression, Naive-Bayes Classification 활용 가능
    * 간단하고 효율적, 종종 모델의 가중치를 직접 보고 중요 특성 식별 가능
* 특성과 타깃간 관계가 복잡한 경우: 다중 신경망 같은 비선형 모델 사용 OR 교차 특성 Intersection Feature 생성 가능

##### 3) 데이터 내 시계열 특징이 있는 경우
* 시계열 정보를 명시적으로 인코딩할 수 있는 모델 사용
    * e.g. ARIMA (AutoRegressive Integrated Moving Average; 자기회귀누적이동평균), RNN (Recurrent Neural Network; 순환 신경망)

##### 4) 각 Data Sample 이 특정 Pattern의 조합으로 이루어져 있는 경우 (e.g. 이미지 분야)
* 각 데이터 샘플이 국부적인 패턴을 포함한다고 판단 되는 경우
    * e.g. 이미지, 음성 인식, 텍스트 분류 
* CNN (Convolutional Neural Network; 합성곱 신경망) 활용 가능
    * CNN: 이동불변성 (translation invariant) 필터를 학습

#### 5.1.3. 데이터셋 분할
* 모델의 핵심 목표는 **사용자의 입력 데이터에 대한 합리적인 예측을 제공하는 것** = **이전에 본적 없는 데이터에서 잘 동작 해야한다**
* 모델이 너무 잘 동작하는 경우, 버그나 데이터 누수 의심
    * 머신러닝의 머피의 법칙: 테스트 데이터에서 모델이 놀라운 성능을 낼수록 모델 파이프라인에 오류가 있을 가능성이 높다 

##### 데이터 분할
* 일반적으로 Train: Valid: Test set 분할
    * Validation SEt: 모델이 본 적 없는 데이터에 일반화 generalization 할 수 있는지 검증
        * 교차 검증 cross-validation: train:valid 분할 후 모델을 훈련하는 괒어을 여러번 반복. 이 경우 검증 세트에 따른 평가 점수의 변동 제어 가능
    * Test set: 모델이 validation set에 편향되는 것을 방지하기 위해 추가로 활용.    
    * **모델링 결정을 내리는 데 테스트 셋의 성능을 사용하지 않는 것이 중요**
        * Why? 과대평가 위험. 테스트 셋의 경우 실전에 투입했을 때 본 적 없는 데이터를 대표하기 때문
 
 ##### 데이터 누수 Data Leakage
 * 데이터 누수는 실전에서 사용자가 사용할 때 얻을 수 없는 정보를 훈련 과정에서 모델이 얻을 때 일어남
 * 1) 시계열 데이터 누수
    * 미래 이벤트를 예측하는 데이터셋에서 --> 훈련하는 모델이 '미래 데이터'를 사용하는 경우
 * 2) 샘플 오염
    * 중복 샘플을 가진 데이터셋에서 --> 훈련할 때 동일 샘플이 검증 세트와 테스트 세트에도 포함되는 경우
    * 한 샘플을 여러 번 측정한 데이터셋에서 훈련할 때 -->. 학습에 사용한 샘플의 다른 측정값이 검증 세트에 포함되는 경우
* 데이터 누수를 피하는 예시
    *  문제 상황: 학생의 수필 점수 예측
    *  랜덤 샘플링하는 경우 문제: 많은 학생들이 여러 개의 수필을 쓰는 썼기 때문에, 동일한 학생의 수필이 훈련 셋과 테스트 셋 동시에 들어갈 수 있음 --> 이전에 본 적없는 학생의 점수는 잘 예측하지 못할 수 있다
    *  해결 방법: 데이터 분할 시 수필 단위가 아닌 학생 단위로 분할

#### 5.1.5. 성능 평가
* 훈련 세트와 검증 세트에 대한 비용 함수 값을 비교함으로써 편향-분산 트레이드오프 (bias-variance tradeoff) 추정 가능
x
* 클래스 불균형이 심한 경우: Precision, Recall, F1-score 활용 가능

### 5.2. 모델 평가: 정확도를 넘어서

### 5.3. 특성 중요도 평가

### 
