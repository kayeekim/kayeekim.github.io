---
layout: post
title:  "[MLPA] Part3/Ch.5 - 모델 훈련과 평가 "
excerpt: "Building Machine LEarning Powered Applications - Part3 - Ch.5 정리"

categories:
  - review
tags:
  - [Books]

toc: true
toc_sticky: true
 
date: 2022-05-11
last_modified_at: 2022-05-11

---

* 해당 블로그는 책 '머신러닝 파워드 애플리케이션 (한빛미디어)' 을 읽고 개인적으로 정리한 글입니다.

* 번역서 코드 주소: https://github.com/rickiepark/ml-powered-applications

#### 머신러닝 전체 과정
Part 1 - 올바른 머신러닝 접근 방법 모색
Part 2 - 초기 프로토타입 제작
**Part 3 - 모델 반복**
Part 4 - 배포와 모니터링

# Part 3 - 모델 반복
* Ch.8 모델 배포 시 고려 사항: 배포 전 마지막 검증 과정 수행 (모델 남용, 부적절 사용 조사 / 안전장치 예상 및 구축)
* Ch.9 배포 방식 선택: 모델을 배포하기 위한 여러가지 도구와 플랫폼 설명 및 그 중 하나를 선택하는 방법
* Ch.10 모델 안전장치 만들기: 모델을 지원할 수 있는 안정적인 제품 환경 구축. 모델 실패를 감지하여 처리 / 모델 성능 최적화 / 반복 훈련 시스템화 포함
* Ch.11 모니터링과 모델 업데이트: 모니터링 / 모니터링 해야하는 이유 / 모델을 모니터링하기 위한 최선의 방법 / 배포 전략에 모니터링 설정을 결합하는 방법 소개.

---

## Ch.5 모델 훈련과 평가
### Summary (+ 5.4. 마치며)
* Part 2 요약: 문제 정의, 문제 해결 계획 세우기, 데이터셋 탐색, 초기 특성 생성 --> 적절한 모델을 훈련하기 위한 충분한 정보 획득
* (해당 장에서 설명하는) 적절한 모델이란? 현재 작업에 적합하고 좋은 성능을 낼 가능성이 높은 모델
* 모델 선택 시 고려 사항
* 모델 평가 시 데이터 분할 방법
* 모델 결과 분석 및 오차 진단

### 5.1. 가장 간단하고 적절한 모델
* 가능한 모든 모델로 시도 및 TEST dataset 의 특정 측정 지표 기준으로 결과를 평가하는 경우 --> 일반적으로 이 방법이 최선이 아님
    * 계산 비용이 높음
    * 모델을 블랙박스 처럼 다룸
    * **머신러닝 모델이 학습하는 과정에서 암묵적으로 데이터에 대해 어떤 가정을 한다는 것**을 완전히 무시 
* 모델마다 데이터에 대한 가정이 다르므로 적합한 작업이 따로 존재

#### 5.1.1. 간단한 모델
* 간단한 모델이란? 1) 빠른 구현 2) 쉬운 이해 3) 배포 가능
* 단순성 비교를 위해 주어진 문제에 맞는 자신만의 비교 표를 만드는 것도 좋음
* 비교 표 항목 예시
    * 1) 구현의 용이성
        * 1-1) 이해하기 쉬운 모델
        * 1-2) 검증된 구현
    * 2) 해석 능력
        * 2-1) 특성 중요도 추출 용이
        * 2-2) 디버깅하기 쉬움
    * 3) 배포 능력
        * 3-1) 추론 시간
        * 3-2) 훈련 시간

##### 1) 빠른 구현 (구현의 용이성)
* 구현이 간단한 모델: 이해하기 쉽고, 튜토리얼에 많이 사용되고, 도움을 얻을 수 있는 모델
* e.g. Keras, Scikit-learn 과 같이 이미 잘 알려진 라이브러리에 있는 모델 사용

##### 2) 쉬운 이해 (해석 능력)
* 모델의 설명 가능성 explainability & 해석 능력 interpretability 란? 예측을 만들게 된 이유 제시 (e.g. 특성 조합 like feature importance)
* 모델의 Explainability 를 통해
    * 모델 편향 확인
    * 예측 결과 향상 방향성 확인
    * 반복과 디버깅 용이
* 모델의 Interpretability 를 통해
    * 더 나은 선택을 하도록 특성 추가, 변경, 제거 방향성 확인 

##### 3) 배포 가능 (배포 능력)
* 모델의 최종 목표는 **사용자에게 가치 있는 서비스를 제공하는 것**
    * 예측 속도: 훈련된 모델이 사용자에게 예측을 제공하는데 시간이 얼마나 소요되는가?  
        * 모델 결과 출력 소요 시간 + 사용자가 요청을 보내고 결과를 받는 과정 소요 시간
        * 변수 전처리, 네트워크 전송, 모델 출력, 사용자에게 보여질 데이터 사이에 필요한 후처리 단계 포함
    * 예상하는 동시 접속자 수 고려: 동시 접속자 수 고려 시 추론 파이프라인이 충분히 빠른지
    * 모델 훈련 시간: 모델 훈련하는데 소요되는 시간, 얼마나 자주 훈련해야하는지 등

#### 5.1.2. 패턴에서 모델로
* 데이터 내 패턴에 따른 적절한 모델 예시

##### 1) Feature (특성) 들 간 Scale 차이가 큰 경우
* 방법 1) 정규화
* 방법 2) 특성 스케일의 차이에 영향을 받지 않는 모델 선택
    * e.g. Tree 계열: Decision Tree, Random Forest, Gradient Boosted Decision Tree, XGBoost
    *  _XGBoost: 그래디언트 부스팅 트리 타입 중 하나로 안정성이 높고 속도가 빨라 실전에서 널리 사용됩니다_

##### 2) Target (Y) 이 Features (Xs) 의 선형 조합인 경우
* 특성의 선형 조합만 사용해 좋은 예측이 가능하다고 판단 되는 경우
* 회귀문제: Linear Regression / 분류문제: Logistic Regression, Naive-Bayes Classification 활용 가능
    * 간단하고 효율적, 종종 모델의 가중치를 직접 보고 중요 특성 식별 가능
* 특성과 타깃간 관계가 복잡한 경우: 다중 신경망 같은 비선형 모델 사용 OR 교차 특성 Intersection Feature 생성 가능

##### 3) 데이터 내 시계열 특징이 있는 경우
* 시계열 정보를 명시적으로 인코딩할 수 있는 모델 사용
    * e.g. ARIMA (AutoRegressive Integrated Moving Average; 자기회귀누적이동평균), RNN (Recurrent Neural Network; 순환 신경망)

##### 4) 각 Data Sample 이 특정 Pattern의 조합으로 이루어져 있는 경우 (e.g. 이미지 분야)
* 각 데이터 샘플이 국부적인 패턴을 포함한다고 판단 되는 경우
    * e.g. 이미지, 음성 인식, 텍스트 분류 
* CNN (Convolutional Neural Network; 합성곱 신경망) 활용 가능
    * CNN: 이동불변성 (translation invariant) 필터를 학습

#### 5.1.3. 데이터셋 분할
* 모델의 핵심 목표는 **사용자의 입력 데이터에 대한 합리적인 예측을 제공하는 것** = **이전에 본적 없는 데이터에서 잘 동작 해야한다**
* 모델이 너무 잘 동작하는 경우, 버그나 데이터 누수 의심
    * 머신러닝의 머피의 법칙: 테스트 데이터에서 모델이 놀라운 성능을 낼수록 모델 파이프라인에 오류가 있을 가능성이 높다 

##### 데이터 분할
* 일반적으로 Train: Valid: Test set 분할
    * Validation SEt: 모델이 본 적 없는 데이터에 일반화 generalization 할 수 있는지 검증
        * 교차 검증 cross-validation: train:valid 분할 후 모델을 훈련하는 괒어을 여러번 반복. 이 경우 검증 세트에 따른 평가 점수의 변동 제어 가능
    * Test set: 모델이 validation set에 편향되는 것을 방지하기 위해 추가로 활용.    
    * **모델링 결정을 내리는 데 테스트 셋의 성능을 사용하지 않는 것이 중요**
        * Why? 과대평가 위험. 테스트 셋의 경우 실전에 투입했을 때 본 적 없는 데이터를 대표하기 때문
 
 ##### 데이터 누수 Data Leakage
 * 데이터 누수는 실전에서 사용자가 사용할 때 얻을 수 없는 정보를 훈련 과정에서 모델이 얻을 때 일어남
 * 1) 시계열 데이터 누수
    * 미래 이벤트를 예측하는 데이터셋에서 --> 훈련하는 모델이 '미래 데이터'를 사용하는 경우
 * 2) 샘플 오염
    * 중복 샘플을 가진 데이터셋에서 --> 훈련할 때 동일 샘플이 검증 세트와 테스트 세트에도 포함되는 경우
    * 한 샘플을 여러 번 측정한 데이터셋에서 훈련할 때 -->. 학습에 사용한 샘플의 다른 측정값이 검증 세트에 포함되는 경우
* 데이터 누수를 피하는 예시
    *  문제 상황: 학생의 수필 점수 예측
    *  랜덤 샘플링하는 경우 문제: 많은 학생들이 여러 개의 수필을 쓰는 썼기 때문에, 동일한 학생의 수필이 훈련 셋과 테스트 셋 동시에 들어갈 수 있음 --> 이전에 본 적없는 학생의 점수는 잘 예측하지 못할 수 있다
    *  해결 방법: 데이터 분할 시 수필 단위가 아닌 학생 단위로 분할

#### 5.1.5. 성능 평가
* 훈련 세트와 검증 세트에 대한 비용 함수 값을 비교함으로써 편향-분산 트레이드오프 (bias-variance tradeoff) 추정 가능
* 클래스 불균형이 심한 경우: Precision, Recall, F1-score 활용 가능

##### 편향-분산 트레이드오프

##### 성능지표 도출 이후
* 성능 검증
    * 성능 지표만으로 평가하면 오해를 일으킬 수 있다 (e.g. 클래스 불균형 문제에서 전체 정확도로 평가하는 경우) 
* 반복
    * 모델 구축은 반복적인 과정. 반복 루프를 시작하는 가장 좋은 방법은 개선할 점과 개선 방법을 찾는 것 
    * 성공적인 모델을 빠르게 구축하는 핵심 열쇠 **모델이 실패하는 특정 이유를 찾아 해결하는 것**
    * 모델이 어려워하는 곳과 파이프라인에서 개선이 필요한 부분을 식별하는 데 성능 지표는 큰 도움이 되지 않음

### 5.2. 모델 평가: 정확도를 넘어서 (부제: 모델 심층 평가)
* 모델이 데이터를 표현할 능력이 있는지,
* 현재 데이터셋이 충분히 균형 잡힌 데이터셋인지
* 현재 데이터셋이 충분히 대표성이 있는 sample을 포함하고 있는지 여부 확인
 
#### 5.2.1. 데이터와 예측 대조하기 
* 하나의 수치로 요약하는 지표 대신에, 데이터의 부분집합을 사용해 정확도, 정밀도, 재현율 같은 성능지표를 따로 계산해서 비교

#### 5.2.2. 오차 행렬 Confusion matrix
* 클래스 별 True vs Prediction 값 비교 가능
* 클래스 수가 많거나 불균형한 데이터셋에 유용
![image](https://user-images.githubusercontent.com/98376833/168807709-26e5843b-dc52-4fc1-8108-498f85dbb5b8.png)
    * 출처: Punn, N. S., & Agarwal, S. (2021). Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray images using fine-tuned deep neural networks. Applied Intelligence, 51(5), 2689-2702.
    * Recall = class-wise (positive) accuracy = Sensitivity

#### 5.2.3. ROC 곡선 (ROC; Receiver Operating Characteristic; 수신자 조작 특성) 
* ROC 곡선이란? 거짓 양성 비율 (FPR; False Positive Rate) 의 함수로 진짜 양성 비율 (TPR; True Positive Rate)를 그린 것.
    * TPR = Recall = class-wise (positive) accuracy = Sensitivity  =  TP / (TP+FN) = positive로 잘 예측 / 전체 positive samples
    * FPR = FP / (FP + TN) = positive 로 잘못 예측 / 전체 negative samples
* 결정임계값 (Decision Threshold) 를 0~1 사이에서 규칙적으로 바꾸면서 각 지점에서 TPR과 FPR을 계산하면 ROC 곡선을 얻을 수 있음
    * 결정임계값: 대부분의 분류 모델은 sample 별로 특정 클래스에 속할 확률 점수를 반환. 추론 시 모델이 만든 확률이 어떤 임계값 이상이면, 샘플을 특정 클래스에 할당할 수 있다는 의미를 가짐. 이 때의 어떤 임계값 (특정 클래스 할당 기준) = 결정임계값. 
    * 대부분의 분류기는 50% 의 확률을 결정 임계값으로 사용하나, 문제에 따라 변화시킬 수 있음.
![image](https://user-images.githubusercontent.com/98376833/168809921-02c91301-ee0f-47ba-a24b-b4ba6b94a265.png)
    * 출처: https://en.wikipedia.org/wiki/Receiver_operating_characteristic    
* ROC 곡선의 이해
    * 왼쪽 아래에서 오른쪽 위로 이어진 대각선 = 무작위 예측
    * 어떤 FPR 구간에도  TPR = 1 에 가까울수록 = 완벽한 모델
* AUC (Area Under the Curve) : ROC 곡선의 아래 면적
    * AUC = 0.5 --> 랜덤한 모델
    * AUC = 1.0 --> 완벽한 모델
* **하지만 실제 애플리케이션에서는 해당 문제에서 가장 유용한 TPR/FPR 비율을 만드는 decision threshold 선택이 필요**
    * **ROC 곡선에 수직선과 수평선을 그어 제품의 요구사항을 나타내면, 단순히 가장 높은 AUC 점수를 구하는 것보다 더 구체적인 목표를 가질 수 있다**
    * 예시) FPR (실제 Negative 를 Positive로 잘못 예측) 한도를 10%로 설정하는 경우, FPR 10% 미만 기준에서 찾을 수 있는 최선의 모델  사용 필요 (e.g. FPR 10% 미만에서의 AUC 값)
* **ROC 곡선은 모델의 예측을 더 보수적으로 혹은 덜 보수적으로 만드냐에 따라 성능이 어떻게 변화하는지 자세한 정보 제공이 가능**

#### 5.2.4.보정 곡선 (Calibration Curve) (= also known as _reliability diagrams_)
* 보정곡선이란? 
    * 분류기의 신뢰도 (reliability) 에 대한 함수. 진짜 양성 샘플의 비율을 나타냄
    * X축: mean predicted probability (평균예측값) / Y축: fraction of positives (양성 샘플의 비율)
    * 모델 예측 확률을 살펴보는 방법으로 **분류문제**에서 사용 가능
    * 예측 분포를 진짜 클래스 분포와 비교하여 보정 calibration 이 잘되었는지 확인  
    * 양성 샘플의 비율 , 평균 예측값 = scikit-learn calibration_curve()
* 보정곡선과 예측값 히스토그램 (평균예측값 별 양성샘플의 count(빈도수)) 을 통해 모델의 출력 확률을 신뢰할 수 있는지 가늠
* 보정 곡선의 이해
    * 왼쪽 아래에서 오른쪽 위로 이어진 대각선 = 완벽한 모델
    * Scikit-learn Calibation curve: https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html
![image](https://user-images.githubusercontent.com/98376833/168813129-3fff7e77-2dd1-4e6b-9de4-7c3e00a4a5d8.png)
* Brier Score (브라이어 점수): 예측 확률과 정답의 차이를 제곱하여 평균낸 것 (0이 최고, 1은 최악) 
    * scikit-learn brier_score_loss()

#### 5.2.5. 오차를 위한 차원 축소
* 차원 축소 기법을 통해 오차 분석 수행 --> 오차가 밀집된 영역을 찾음
* 차원 축소를 통해 시각화 한 후, 데이터 포인터 별로 모델 성능에 따라 색깔을 달리하여 오차를 구별하거나
* 데이터에 군집 알고리즘을 적용한 후, 각 클러스터에서 모델의 성능을 측정하고 가장 성능이 나쁜 클러스터 확인. --> 이 클러스터 안의 샘플을 조사하여 필요한 특성 생성 가능 



### 5.3. 특성 중요도 평가

###
